---
layout: post
title: CICD
date: 2020-02-11
tags: javascript tutorial serverless sam
author: Matthew Tyler
image: img/serverless-express.png
---

# Introduction

Most of us are familiar with the process of building and running software; from writing our first few lines, to compiling, to seeing 'hello world' printed on a screen. Most professional software engineers will be familiar with various practices designed to help software engineers build and release software. Having said that, I've yet to see any two companies (or even a small group of engineers) have similar ideas on what constitutes the ideal way to automate their software delivery process. I'm not referring to things like language/framework choices, or even coding styles; instead I refer to the various practices that have sprung up around the software world in the last ten to twenty years. Pair Programming? BDD? Pull Requests? Version Control? CI? CD? non-prod? prod? staging? manual gates? etc. 

The tooling that developers use both in and around the release process is on that I find most interesting. It is one of the most critical stages in the software process, yet is regularly the most brittle, insecure, and misunderstood tools in most organizations. For those of you at large companies, ask around your office: just how many people /really/ understand your build tooling? It's not uncommon for their to be only one to be one or two build 'wizards' that really understand the companies release process end-to-end. This is a shame for a few reasons. It is the one place that all work flows through; having knowledge and an appreciatiation of the process means that more developers can contribute to it's improvement, thereby rapidly accelerating the productivity of not only themselves, but their peers as well. Likewise, a good build and release process confers a good knowledge of the frameworks and tools you are using. This is knowledge that can be employed to be a more productive programmer in your day-to-day.

I intend for this series to serve a few purposes;

- To serve as introduction to some common types of build & release processes

  It's entirely likely that you may spend an entire career and never release a library to public package repository. That said, having an understand of the process and challenges in doing so may help you in solving other problems. You may be struggling with to decide the best way to build and release your own projects, and I hope that you be able to derive some inspiration from the examples contained within.

- To allow the read to observe a build & release process as it increases in sophistication

  The education most receive in software delivery is one that comes via a trial-by-fire. You start with a small solution to a small problem and iterate from there. I think it was easy to do this in years gone by when times where simpler, but the fast-paced nature of the world has become fairly unforgiving, and there are fewer low-risk opportunities to really touch-on software release processes. Increasing levels of abstraction and the proliferation of managed services make it harder to gain context and to understand the 'why', which is neccesary when faced with obstacles that you may be unfamiliar with.

- To understand the software is distributed and consumed in different ways, as this inevitably influences the process

  Software is consumed in wildly different ways depending on the who it is for. Software is installed on desktops using binaries retrieved via FTP. Libraries are distributed via various package manager. SaaS is commonly delivered via web browser. How your software is delivered and consumed has a marked effect on your build & release process.

- Evaluate different CI/CD processes within the lens of the AWS Well-Architected Framework

  The automated release process that many developers use are almost as the software they are releasing. They are living applications themselves, even if many companies don't realise it. They have many of the same opportunities and threats to their existance as other applications - sometimes more so. The Well-Architect Framework identifies 5 Key Pillars: Operational Excellence, Security, Reliability, Performance Efficiency, and Cost Optimization. We will evaluate our evolving release mechanisms against these pillars to understand their weaknesses and look for improvements.

Examples will primarily be within the AWS ecosystem, using AWS specific tooling. I have a fair few reasons for this, and chief among these is the popularity of AWS will likely make this relevant to a larger audience. Many are critical of the developer experience around AWS tooling (including myself at times), with complaints usually leveled at how byzantine the services are. For a guide like this though, the primitive nature of the services is an effective way to illustrate various boundaries between different stages in the process. AWS is fairly well known for releasing 'building blocks'; services that may offer an incomplete experience, but often serve as stepping stones to creating services that are more featurful or provide better abstractions; consider the evolution from EC2 Virtual Machines, to EC2 Container Service, to Fargate. We will consider the various release tooling within the AWS Code* suite in a similar light.

I don't intend for this to be the defacto guide to CI/CD mechanisms. I don't consider it to be source of truth for various definitions of practices in the community. I am sure there will be arguments for and against my particular understanding of different terms and practices. It's merely the understanding I've gained from working in and around CI/CD tooling over the last decade, and the conclusions I've drawn from that experience. This is weighted heavily to a create a working-persons guide to practical software delivery, rather than an expression of ideologic purity that is often at odds with the reality of the typical developers day-to-day.

# Definitions

Future installments will go into details of specific examples. Firstly we need to set some definitions and understand the main concepts that form the modern software delivery apparatus.

## (Distributed) Version Control Systems

Of anything in software development unrelated to the process of writing code, version control systems are probably the most impactful tools on a developers career. When I first began coding, I had no idea what a version control system was. When I later went to University during the mid to late 2000's, I was not introduced to version control until I had almost graduated. Up until then, my peers and I had gotten by the common practice of appending 'final' repeatedly to the end of the name of a zip file. I would not interact with a VCS until my first development job in around 2010, not begin using Git until two years later, and not become comfortable with it a few years after that.

At the time I was beginning my career there were several different systems vying for the market but it would seem Git has won the war. Millions of developers are using GitHub, of which Git is the defacto system of choice. Git itself has a long and storied history, created by and out of Linus Torvalds discontent with the licencing fees associated with the system used by the Linux Kernel at the time. As such, it retains a long list of features designed to work with the Linux Kernel development process that would seem completely foreign to the vast majority of the development community, most of whom are probably used to the kinds of workflows that are made easy by GitHub. I mean this as a comfort; if you are worried about the complexity of Git, stop worrying. None of us know how to use every bit of it either. Take the parts of Git you know as trusted ground, whilst viewing the parts you don't as an exciting frontier for further discovery at the right time. That attitude will take you further than a fear.

Modern software would simply not function without Git or something like that. Maintaining a complete history of your code at certain points of time is the only way we can trace back what is running in our users hands to what we wrote. That link is critical to working out how to resolve issues. If the source code is the scene of the crime - version control is the video evidence of it.

Git is perhaps most importantly, an enabler of collaboration. Many developers can contribute to the development of software at the same time all on the same code base. This coordination of software changes ensures that software development is capable of scaling as the number of contributers increases. It is not perfect, but it will do.

## Continous Integration

It is important to establish whether the contributions of many developers are features or regressions. Simply allowing developers to contribute directly to a release without establishing whether existing code continues to work post-these-changes is generally considered by users of that software to be particularly important. But users also want new features as fast as possible, and they also want those features to work too. In the past limited resources and the lack of the tooling we are afforded today led to long and expensive manual testing cycles and slow releases, or software that released frequently but was constantly broken in various different ways.

Continuous Integration done right is a means to solve this problem. The 'common' implementation of continuous integration functions as thus;

1. The developer creates a set of changes to a code base, and creates a 'request' to merge her changes into the main code base.

2. As part of this request, and automatic process is kicked off. The process runs a suite of tests written both against the existing base and the new changes.

3. If these changes pass, the code is considered functionally healthy enough to be merged into the main code base, in effect becoming a part of it.

In the 'purest' form of continuous integration, there is no manual intervention by a human to review the code. Provided the test coverage of the entire code base doesn't drop, and the tests do not fail, that is enough for the system to automatically accept the new code. In practice there is usually  some manual approval required before accepting the code. Code reviews are usually less about the explicit functionality and more about checking that the style, convention and quality of the incoming code is of acceptable standard. Determining the values of the attributes cannot always be determined by automation, although technology is getting close to doing so. Code that is produce by pair-programming may not go through a manual approval - the act of writing code together should be enough quality control in most circumstances.

Continuous Integration gives a code base a particularly powerful property - that this code base could be released to a user at any time, and the software should work. You cannot have confidence this property will hold without a robust test suite that is executed on every change. Software that is in a shippable state, that is missing promised functionality, is still software that can be sold. That is still preferable to software that does not ship, and can't be sold.

In summation, Continuous Integration is an approach designed to ensure that software changes are accepted into the main software corpus as fast as possible, without a degradation in the overally quality of the code, and ensuring that the software could be released at any time. Other processes, like continuous deployment, and continuous delivery, cannot function with its presence. After version control, establishing a strong continous integration mechanism is the next element to focus on for a healthy software delivery process.

## Package Management

## Continuous Delivery

## Continuous Deployment

## Environments

## Pipelines



